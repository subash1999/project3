{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.0-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36064bit31dadfea6e644b5a81effafd042eaf5e",
   "display_name": "Python 3.6.0 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "import completed\n"
    }
   ],
   "source": [
    "import os,sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, SelectFdr, SelectFpr, SelectFwe\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE,RFECV\n",
    "from sklearn.feature_selection import chi2,f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import ParameterGrid, GridSearchCV\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression,LassoCV, Lasso\n",
    "from sklearn.ensemble import ExtraTreesClassifier, BaggingClassifier, VotingClassifier, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.metrics import  accuracy_score,auc,average_precision_score,roc_auc_score, recall_score,f1_score, log_loss, fbeta_score, confusion_matrix, precision_recall_curve,classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from tpot import TPOTClassifier\n",
    "from ReliefF import ReliefF\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE,SMOTENC,ADASYN, BorderlineSMOTE, KMeansSMOTE, SVMSMOTE,RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from sklearn.preprocessing import Normalizer,normalize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier,GradientBoostingClassifier,StackingClassifier,VotingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pickle\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from matplotlib import pyplot\n",
    "import time\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "from multiprocessing import Process,Pool,Manager\n",
    "\n",
    "from preprocessing.Normalize import Normalize\n",
    "import helper.SeriesHelper as series_helper\n",
    "\n",
    "print(\"import completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "train imported from normal \n"
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = Normalize().get_train_test()\n",
    "\n",
    "print(\"train imported from normal \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizing k for of selectkbest for boderline  \n",
    "borderline = BorderlineSMOTE(random_state=27,k_neighbors=30,n_jobs=5,m_neighbors=10)\n",
    "temp_X_train, temp_y_train = borderline.fit_sample(X_train, y_train)\n",
    "temp_X_test,temp_y_test = borderline.fit_sample(X_test, y_test)\n",
    "\n",
    "temp_X_train = normalize(temp_X_train)\n",
    "temp_X_test = normalize(temp_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_f1():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=f_classif,k=860).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=35,n_jobs=7).fit(xtr,ytr)\n",
    "    pred = knn.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"f1_score :: \",f1_score(yte,pred))\n",
    "    return [knn.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_roc_auc():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=79).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=35,n_jobs=7).fit(xtr,ytr)\n",
    "    pred = knn.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"roc_auc_score :: \",roc_auc_score(yte,pred))\n",
    "    return [knn.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_precision():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=79).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=35,n_jobs=7).fit(xtr,ytr)\n",
    "    pred = knn.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"precision :: \",average_precision_score(yte,pred))\n",
    "    return [knn.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_recall():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=f_classif,k=938).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=35,n_jobs=7).fit(xtr,ytr)\n",
    "    pred = knn.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"recall_score :: \",recall_score(yte,pred))\n",
    "    return [knn.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_accuracy():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=79).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=35,n_jobs=7).fit(xtr,ytr)\n",
    "    pred = knn.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"accuracy :: \",accuracy_score(yte,pred))\n",
    "    return [knn.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_accuracy():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=921).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    mlp = MLPClassifier().fit(xtr,ytr)\n",
    "    pred = mlp.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"accuracy :: \",accuracy_score(yte,pred))\n",
    "    return [mlp.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_precision():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=921).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    mlp = MLPClassifier().fit(xtr,ytr)\n",
    "    pred = mlp.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"average_precision_score :: \",average_precision_score(yte,pred))\n",
    "    return [mlp.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_recall():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=21).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    mlp = MLPClassifier().fit(xtr,ytr)\n",
    "    pred = mlp.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"recall_score :: \",recall_score(yte,pred))\n",
    "    return [mlp.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_f1():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=36).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    mlp = MLPClassifier().fit(xtr,ytr)\n",
    "    pred = mlp.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"recall_score :: \",f1_score(yte,pred))\n",
    "    return [mlp.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_roc_auc():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=921).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    mlp = MLPClassifier().fit(xtr,ytr)\n",
    "    pred = mlp.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"roc_auc_score :: \",roc_auc_score(yte,pred))\n",
    "    return [mlp.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_accuracy():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=857).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis().fit(xtr,ytr)\n",
    "    pred = lda.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"accuracy :: \",accuracy_score(yte,pred))\n",
    "    return [lda.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_precision():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=857).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis().fit(xtr,ytr)\n",
    "    pred = lda.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"average_precision :: \",average_precision_score(yte,pred))\n",
    "    return [lda.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_recall():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=857).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis().fit(xtr,ytr)\n",
    "    pred = lda.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"recall :: \",recall_score(yte,pred))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_f1():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=857).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis().fit(xtr,ytr)\n",
    "    pred = lda.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"f1 :: \",f1_score(yte,pred))\n",
    "    return [lda.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_roc_auc():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=857).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis().fit(xtr,ytr)\n",
    "    pred = lda.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"roc_auc :: \",roc_auc_score(yte,pred))\n",
    "    return [lda.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qda_accuracy():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=41).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    qda = QuadraticDiscriminantAnalysis().fit(xtr,ytr)\n",
    "    pred = qda.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"accuracy :: \",accuracy_score(yte,pred))\n",
    "    return [qda.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qda_precision():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=41).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    qda = QuadraticDiscriminantAnalysis().fit(xtr,ytr)\n",
    "    pred = qda.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"precision :: \",average_precision_score(yte,pred))\n",
    "    return [qda.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qda_recall():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=f_classif,k=1).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    qda = QuadraticDiscriminantAnalysis().fit(xtr,ytr)\n",
    "    pred = qda.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"recall :: \",recall_score(yte,pred))\n",
    "    return [qda.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qda_f1():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=mutual_info_classif,k=5).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    qda = QuadraticDiscriminantAnalysis().fit(xtr,ytr)\n",
    "    pred = qda.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"f1 :: \",f1_score(yte,pred))\n",
    "    return [qda.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qda_roc_auc():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=41).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    qda = QuadraticDiscriminantAnalysis().fit(xtr,ytr)\n",
    "    pred = qda.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"roc_auc :: \",roc_auc_score(yte,pred))\n",
    "    return [qda.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_accuracy():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=27).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    svc = SVC(random_state=27).fit(xtr,ytr)\n",
    "    pred = svc.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"accuracy :: \",accuracy_score(yte,pred))\n",
    "    return [svc.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_precision():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=27).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    svc = SVC(random_state=27).fit(xtr,ytr)\n",
    "    pred = svc.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"average_precision :: \",average_precision_score(yte,pred))\n",
    "    return [svc.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_recall():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=27).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    svc = SVC(random_state=27).fit(xtr,ytr)\n",
    "    pred = svc.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"recall :: \",recall_score(yte,pred))\n",
    "    return [svc.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_f1():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=27).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    svc = SVC(random_state=27).fit(xtr,ytr)\n",
    "    pred = svc.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"f1 :: \",f1_score(yte,pred))\n",
    "    return [svc.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_roc_auc():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=27).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    svc = SVC(random_state=27).fit(xtr,ytr)\n",
    "    pred = svc.predict(xte)\n",
    "    print(classification_report(yte,pred))\n",
    "    print(\"roc_auc :: \",roc_auc_score(yte,pred))\n",
    "    return [svc.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=859).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    xgb = XGBClassifier(random_state=27).fit(xtr,ytr)\n",
    "    pred = xgb.predict(xte)\n",
    "    # print(classification_report(yte,pred))\n",
    "    print(\"accuracy, precision, recall, f1_score, roc_auc_score:: \",accuracy_score(yte,pred),average_precision_score(yte,pred),recall_score(yte,pred),f1_score(yte,pred),roc_auc_score(yte,pred))\n",
    "    # print(confusion_matrix(yte,pred))\n",
    "    return [xgb.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm():\n",
    "    xtr = temp_X_train\n",
    "    ytr = temp_y_train\n",
    "    xte = temp_X_test\n",
    "    yte = temp_y_test\n",
    "\n",
    "    best = SelectKBest(score_func=chi2,k=562).fit(xtr,ytr)\n",
    "    xtr = best.transform(xtr)\n",
    "    xte = best.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "    xtr = model.transform(xtr)\n",
    "    xte = model.transform(xte)\n",
    "\n",
    "    lgbm = LGBMClassifier(random_state=27).fit(xtr,ytr)\n",
    "    pred = lgbm.predict(xte)\n",
    "    # print(classification_report(yte,pred))\n",
    "    print(\"accuracy, precision, recall, f1_score, roc_auc_score:: \",accuracy_score(yte,pred),average_precision_score(yte,pred),recall_score(yte,pred),f1_score(yte,pred),roc_auc_score(yte,pred))\n",
    "    # print(confusion_matrix(yte,pred))\n",
    "    return [lgbm.predict(xtr),pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filename):\n",
    "    with open(filename+'.pickle', 'rb') as config_dictionary_file:\n",
    "        return pickle.load(config_dictionary_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = load_pickle(\"__stacked__py__linearsvc_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['no_of_genes','score_func','accuracy','precision','recall_score','f1_score','roc_auc'],data=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>no_of_genes</th>\n      <th>score_func</th>\n      <th>accuracy</th>\n      <th>precision</th>\n      <th>recall_score</th>\n      <th>f1_score</th>\n      <th>roc_auc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>561</th>\n      <td>562</td>\n      <td>chi2</td>\n      <td>0.669565</td>\n      <td>0.620337</td>\n      <td>0.573913</td>\n      <td>0.634615</td>\n      <td>0.669565</td>\n    </tr>\n    <tr>\n      <th>904</th>\n      <td>905</td>\n      <td>chi2</td>\n      <td>0.665217</td>\n      <td>0.619979</td>\n      <td>0.530435</td>\n      <td>0.613065</td>\n      <td>0.665217</td>\n    </tr>\n    <tr>\n      <th>936</th>\n      <td>937</td>\n      <td>chi2</td>\n      <td>0.663043</td>\n      <td>0.617700</td>\n      <td>0.530435</td>\n      <td>0.611529</td>\n      <td>0.663043</td>\n    </tr>\n    <tr>\n      <th>928</th>\n      <td>929</td>\n      <td>chi2</td>\n      <td>0.654348</td>\n      <td>0.609596</td>\n      <td>0.521739</td>\n      <td>0.601504</td>\n      <td>0.654348</td>\n    </tr>\n    <tr>\n      <th>625</th>\n      <td>626</td>\n      <td>chi2</td>\n      <td>0.654348</td>\n      <td>0.608484</td>\n      <td>0.534783</td>\n      <td>0.607407</td>\n      <td>0.654348</td>\n    </tr>\n    <tr>\n      <th>632</th>\n      <td>633</td>\n      <td>chi2</td>\n      <td>0.654348</td>\n      <td>0.607116</td>\n      <td>0.552174</td>\n      <td>0.615012</td>\n      <td>0.654348</td>\n    </tr>\n    <tr>\n      <th>744</th>\n      <td>745</td>\n      <td>chi2</td>\n      <td>0.654348</td>\n      <td>0.614963</td>\n      <td>0.469565</td>\n      <td>0.576000</td>\n      <td>0.654348</td>\n    </tr>\n    <tr>\n      <th>668</th>\n      <td>669</td>\n      <td>chi2</td>\n      <td>0.654348</td>\n      <td>0.609217</td>\n      <td>0.526087</td>\n      <td>0.603491</td>\n      <td>0.654348</td>\n    </tr>\n    <tr>\n      <th>876</th>\n      <td>877</td>\n      <td>chi2</td>\n      <td>0.652174</td>\n      <td>0.607417</td>\n      <td>0.521739</td>\n      <td>0.600000</td>\n      <td>0.652174</td>\n    </tr>\n    <tr>\n      <th>667</th>\n      <td>668</td>\n      <td>chi2</td>\n      <td>0.652174</td>\n      <td>0.607417</td>\n      <td>0.521739</td>\n      <td>0.600000</td>\n      <td>0.652174</td>\n    </tr>\n    <tr>\n      <th>782</th>\n      <td>783</td>\n      <td>chi2</td>\n      <td>0.652174</td>\n      <td>0.605351</td>\n      <td>0.547826</td>\n      <td>0.611650</td>\n      <td>0.652174</td>\n    </tr>\n    <tr>\n      <th>743</th>\n      <td>744</td>\n      <td>chi2</td>\n      <td>0.650000</td>\n      <td>0.607143</td>\n      <td>0.500000</td>\n      <td>0.588235</td>\n      <td>0.650000</td>\n    </tr>\n    <tr>\n      <th>944</th>\n      <td>945</td>\n      <td>chi2</td>\n      <td>0.650000</td>\n      <td>0.605988</td>\n      <td>0.513043</td>\n      <td>0.594458</td>\n      <td>0.650000</td>\n    </tr>\n    <tr>\n      <th>558</th>\n      <td>559</td>\n      <td>chi2</td>\n      <td>0.650000</td>\n      <td>0.603911</td>\n      <td>0.539130</td>\n      <td>0.606357</td>\n      <td>0.650000</td>\n    </tr>\n    <tr>\n      <th>855</th>\n      <td>856</td>\n      <td>chi2</td>\n      <td>0.650000</td>\n      <td>0.605988</td>\n      <td>0.513043</td>\n      <td>0.594458</td>\n      <td>0.650000</td>\n    </tr>\n    <tr>\n      <th>553</th>\n      <td>554</td>\n      <td>chi2</td>\n      <td>0.650000</td>\n      <td>0.604571</td>\n      <td>0.530435</td>\n      <td>0.602469</td>\n      <td>0.650000</td>\n    </tr>\n    <tr>\n      <th>718</th>\n      <td>719</td>\n      <td>chi2</td>\n      <td>0.650000</td>\n      <td>0.606748</td>\n      <td>0.504348</td>\n      <td>0.590331</td>\n      <td>0.650000</td>\n    </tr>\n    <tr>\n      <th>961</th>\n      <td>962</td>\n      <td>chi2</td>\n      <td>0.650000</td>\n      <td>0.602973</td>\n      <td>0.552174</td>\n      <td>0.612048</td>\n      <td>0.650000</td>\n    </tr>\n    <tr>\n      <th>840</th>\n      <td>841</td>\n      <td>chi2</td>\n      <td>0.650000</td>\n      <td>0.603591</td>\n      <td>0.543478</td>\n      <td>0.608273</td>\n      <td>0.650000</td>\n    </tr>\n    <tr>\n      <th>304</th>\n      <td>305</td>\n      <td>chi2</td>\n      <td>0.650000</td>\n      <td>0.604913</td>\n      <td>0.526087</td>\n      <td>0.600496</td>\n      <td>0.650000</td>\n    </tr>\n    <tr>\n      <th>305</th>\n      <td>306</td>\n      <td>chi2</td>\n      <td>0.650000</td>\n      <td>0.604913</td>\n      <td>0.526087</td>\n      <td>0.600496</td>\n      <td>0.650000</td>\n    </tr>\n    <tr>\n      <th>306</th>\n      <td>307</td>\n      <td>chi2</td>\n      <td>0.650000</td>\n      <td>0.604913</td>\n      <td>0.526087</td>\n      <td>0.600496</td>\n      <td>0.650000</td>\n    </tr>\n    <tr>\n      <th>653</th>\n      <td>654</td>\n      <td>chi2</td>\n      <td>0.647826</td>\n      <td>0.603830</td>\n      <td>0.513043</td>\n      <td>0.592965</td>\n      <td>0.647826</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>210</td>\n      <td>chi2</td>\n      <td>0.647826</td>\n      <td>0.601529</td>\n      <td>0.543478</td>\n      <td>0.606796</td>\n      <td>0.647826</td>\n    </tr>\n    <tr>\n      <th>943</th>\n      <td>944</td>\n      <td>chi2</td>\n      <td>0.647826</td>\n      <td>0.603478</td>\n      <td>0.517391</td>\n      <td>0.595000</td>\n      <td>0.647826</td>\n    </tr>\n    <tr>\n      <th>641</th>\n      <td>642</td>\n      <td>chi2</td>\n      <td>0.647826</td>\n      <td>0.601229</td>\n      <td>0.547826</td>\n      <td>0.608696</td>\n      <td>0.647826</td>\n    </tr>\n    <tr>\n      <th>635</th>\n      <td>636</td>\n      <td>chi2</td>\n      <td>0.647826</td>\n      <td>0.604191</td>\n      <td>0.508696</td>\n      <td>0.590909</td>\n      <td>0.647826</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>567</td>\n      <td>chi2</td>\n      <td>0.647826</td>\n      <td>0.600366</td>\n      <td>0.560870</td>\n      <td>0.614286</td>\n      <td>0.647826</td>\n    </tr>\n    <tr>\n      <th>648</th>\n      <td>649</td>\n      <td>chi2</td>\n      <td>0.647826</td>\n      <td>0.604560</td>\n      <td>0.504348</td>\n      <td>0.588832</td>\n      <td>0.647826</td>\n    </tr>\n    <tr>\n      <th>957</th>\n      <td>958</td>\n      <td>chi2</td>\n      <td>0.647826</td>\n      <td>0.603478</td>\n      <td>0.517391</td>\n      <td>0.595000</td>\n      <td>0.647826</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>157</th>\n      <td>158</td>\n      <td>chi2</td>\n      <td>0.532609</td>\n      <td>0.517823</td>\n      <td>0.382609</td>\n      <td>0.450128</td>\n      <td>0.532609</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>19</td>\n      <td>chi2</td>\n      <td>0.530435</td>\n      <td>0.516316</td>\n      <td>0.452174</td>\n      <td>0.490566</td>\n      <td>0.530435</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>39</td>\n      <td>chi2</td>\n      <td>0.530435</td>\n      <td>0.516272</td>\n      <td>0.469565</td>\n      <td>0.500000</td>\n      <td>0.530435</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>43</td>\n      <td>chi2</td>\n      <td>0.530435</td>\n      <td>0.516272</td>\n      <td>0.469565</td>\n      <td>0.500000</td>\n      <td>0.530435</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>42</td>\n      <td>chi2</td>\n      <td>0.530435</td>\n      <td>0.516272</td>\n      <td>0.469565</td>\n      <td>0.500000</td>\n      <td>0.530435</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>chi2</td>\n      <td>0.530435</td>\n      <td>0.516186</td>\n      <td>0.508696</td>\n      <td>0.520000</td>\n      <td>0.530435</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>41</td>\n      <td>chi2</td>\n      <td>0.530435</td>\n      <td>0.516272</td>\n      <td>0.469565</td>\n      <td>0.500000</td>\n      <td>0.530435</td>\n    </tr>\n    <tr>\n      <th>155</th>\n      <td>156</td>\n      <td>chi2</td>\n      <td>0.526087</td>\n      <td>0.513933</td>\n      <td>0.408696</td>\n      <td>0.463054</td>\n      <td>0.526087</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>chi2</td>\n      <td>0.526087</td>\n      <td>0.513885</td>\n      <td>0.430435</td>\n      <td>0.475962</td>\n      <td>0.526087</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>chi2</td>\n      <td>0.526087</td>\n      <td>0.513885</td>\n      <td>0.430435</td>\n      <td>0.475962</td>\n      <td>0.526087</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>chi2</td>\n      <td>0.526087</td>\n      <td>0.513885</td>\n      <td>0.430435</td>\n      <td>0.475962</td>\n      <td>0.526087</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>44</td>\n      <td>chi2</td>\n      <td>0.523913</td>\n      <td>0.512592</td>\n      <td>0.473913</td>\n      <td>0.498856</td>\n      <td>0.523913</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>24</td>\n      <td>chi2</td>\n      <td>0.519565</td>\n      <td>0.510216</td>\n      <td>0.460870</td>\n      <td>0.489607</td>\n      <td>0.519565</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>chi2</td>\n      <td>0.519565</td>\n      <td>0.510225</td>\n      <td>0.452174</td>\n      <td>0.484848</td>\n      <td>0.519565</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>chi2</td>\n      <td>0.519565</td>\n      <td>0.510181</td>\n      <td>0.500000</td>\n      <td>0.509978</td>\n      <td>0.519565</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>27</td>\n      <td>chi2</td>\n      <td>0.519565</td>\n      <td>0.510216</td>\n      <td>0.460870</td>\n      <td>0.489607</td>\n      <td>0.519565</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>chi2</td>\n      <td>0.519565</td>\n      <td>0.510225</td>\n      <td>0.452174</td>\n      <td>0.484848</td>\n      <td>0.519565</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>chi2</td>\n      <td>0.517391</td>\n      <td>0.509043</td>\n      <td>0.452174</td>\n      <td>0.483721</td>\n      <td>0.517391</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>chi2</td>\n      <td>0.517391</td>\n      <td>0.508996</td>\n      <td>0.521739</td>\n      <td>0.519481</td>\n      <td>0.517391</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>chi2</td>\n      <td>0.517391</td>\n      <td>0.508996</td>\n      <td>0.521739</td>\n      <td>0.519481</td>\n      <td>0.517391</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>chi2</td>\n      <td>0.517391</td>\n      <td>0.508996</td>\n      <td>0.521739</td>\n      <td>0.519481</td>\n      <td>0.517391</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>22</td>\n      <td>chi2</td>\n      <td>0.510870</td>\n      <td>0.505550</td>\n      <td>0.521739</td>\n      <td>0.516129</td>\n      <td>0.510870</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>chi2</td>\n      <td>0.510870</td>\n      <td>0.505565</td>\n      <td>0.465217</td>\n      <td>0.487472</td>\n      <td>0.510870</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>chi2</td>\n      <td>0.510870</td>\n      <td>0.505565</td>\n      <td>0.465217</td>\n      <td>0.487472</td>\n      <td>0.510870</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>chi2</td>\n      <td>0.510870</td>\n      <td>0.505565</td>\n      <td>0.465217</td>\n      <td>0.487472</td>\n      <td>0.510870</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>18</td>\n      <td>chi2</td>\n      <td>0.506522</td>\n      <td>0.503308</td>\n      <td>0.456522</td>\n      <td>0.480549</td>\n      <td>0.506522</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>20</td>\n      <td>chi2</td>\n      <td>0.506522</td>\n      <td>0.503308</td>\n      <td>0.456522</td>\n      <td>0.480549</td>\n      <td>0.506522</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>21</td>\n      <td>chi2</td>\n      <td>0.504348</td>\n      <td>0.502197</td>\n      <td>0.413043</td>\n      <td>0.454545</td>\n      <td>0.504348</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>23</td>\n      <td>chi2</td>\n      <td>0.502174</td>\n      <td>0.501092</td>\n      <td>0.443478</td>\n      <td>0.471132</td>\n      <td>0.502174</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>chi2</td>\n      <td>0.489130</td>\n      <td>0.494699</td>\n      <td>0.430435</td>\n      <td>0.457275</td>\n      <td>0.489130</td>\n    </tr>\n  </tbody>\n</table>\n<p>999 rows × 7 columns</p>\n</div>",
      "text/plain": "     no_of_genes score_func  accuracy  precision  recall_score  f1_score  \\\n561          562       chi2  0.669565   0.620337      0.573913  0.634615   \n904          905       chi2  0.665217   0.619979      0.530435  0.613065   \n936          937       chi2  0.663043   0.617700      0.530435  0.611529   \n928          929       chi2  0.654348   0.609596      0.521739  0.601504   \n625          626       chi2  0.654348   0.608484      0.534783  0.607407   \n632          633       chi2  0.654348   0.607116      0.552174  0.615012   \n744          745       chi2  0.654348   0.614963      0.469565  0.576000   \n668          669       chi2  0.654348   0.609217      0.526087  0.603491   \n876          877       chi2  0.652174   0.607417      0.521739  0.600000   \n667          668       chi2  0.652174   0.607417      0.521739  0.600000   \n782          783       chi2  0.652174   0.605351      0.547826  0.611650   \n743          744       chi2  0.650000   0.607143      0.500000  0.588235   \n944          945       chi2  0.650000   0.605988      0.513043  0.594458   \n558          559       chi2  0.650000   0.603911      0.539130  0.606357   \n855          856       chi2  0.650000   0.605988      0.513043  0.594458   \n553          554       chi2  0.650000   0.604571      0.530435  0.602469   \n718          719       chi2  0.650000   0.606748      0.504348  0.590331   \n961          962       chi2  0.650000   0.602973      0.552174  0.612048   \n840          841       chi2  0.650000   0.603591      0.543478  0.608273   \n304          305       chi2  0.650000   0.604913      0.526087  0.600496   \n305          306       chi2  0.650000   0.604913      0.526087  0.600496   \n306          307       chi2  0.650000   0.604913      0.526087  0.600496   \n653          654       chi2  0.647826   0.603830      0.513043  0.592965   \n209          210       chi2  0.647826   0.601529      0.543478  0.606796   \n943          944       chi2  0.647826   0.603478      0.517391  0.595000   \n641          642       chi2  0.647826   0.601229      0.547826  0.608696   \n635          636       chi2  0.647826   0.604191      0.508696  0.590909   \n566          567       chi2  0.647826   0.600366      0.560870  0.614286   \n648          649       chi2  0.647826   0.604560      0.504348  0.588832   \n957          958       chi2  0.647826   0.603478      0.517391  0.595000   \n..           ...        ...       ...        ...           ...       ...   \n157          158       chi2  0.532609   0.517823      0.382609  0.450128   \n18            19       chi2  0.530435   0.516316      0.452174  0.490566   \n38            39       chi2  0.530435   0.516272      0.469565  0.500000   \n42            43       chi2  0.530435   0.516272      0.469565  0.500000   \n41            42       chi2  0.530435   0.516272      0.469565  0.500000   \n3              4       chi2  0.530435   0.516186      0.508696  0.520000   \n40            41       chi2  0.530435   0.516272      0.469565  0.500000   \n155          156       chi2  0.526087   0.513933      0.408696  0.463054   \n8              9       chi2  0.526087   0.513885      0.430435  0.475962   \n10            11       chi2  0.526087   0.513885      0.430435  0.475962   \n9             10       chi2  0.526087   0.513885      0.430435  0.475962   \n43            44       chi2  0.523913   0.512592      0.473913  0.498856   \n23            24       chi2  0.519565   0.510216      0.460870  0.489607   \n13            14       chi2  0.519565   0.510225      0.452174  0.484848   \n4              5       chi2  0.519565   0.510181      0.500000  0.509978   \n26            27       chi2  0.519565   0.510216      0.460870  0.489607   \n14            15       chi2  0.519565   0.510225      0.452174  0.484848   \n15            16       chi2  0.517391   0.509043      0.452174  0.483721   \n2              3       chi2  0.517391   0.508996      0.521739  0.519481   \n0              1       chi2  0.517391   0.508996      0.521739  0.519481   \n1              2       chi2  0.517391   0.508996      0.521739  0.519481   \n21            22       chi2  0.510870   0.505550      0.521739  0.516129   \n7              8       chi2  0.510870   0.505565      0.465217  0.487472   \n6              7       chi2  0.510870   0.505565      0.465217  0.487472   \n5              6       chi2  0.510870   0.505565      0.465217  0.487472   \n17            18       chi2  0.506522   0.503308      0.456522  0.480549   \n19            20       chi2  0.506522   0.503308      0.456522  0.480549   \n20            21       chi2  0.504348   0.502197      0.413043  0.454545   \n22            23       chi2  0.502174   0.501092      0.443478  0.471132   \n16            17       chi2  0.489130   0.494699      0.430435  0.457275   \n\n      roc_auc  \n561  0.669565  \n904  0.665217  \n936  0.663043  \n928  0.654348  \n625  0.654348  \n632  0.654348  \n744  0.654348  \n668  0.654348  \n876  0.652174  \n667  0.652174  \n782  0.652174  \n743  0.650000  \n944  0.650000  \n558  0.650000  \n855  0.650000  \n553  0.650000  \n718  0.650000  \n961  0.650000  \n840  0.650000  \n304  0.650000  \n305  0.650000  \n306  0.650000  \n653  0.647826  \n209  0.647826  \n943  0.647826  \n641  0.647826  \n635  0.647826  \n566  0.647826  \n648  0.647826  \n957  0.647826  \n..        ...  \n157  0.532609  \n18   0.530435  \n38   0.530435  \n42   0.530435  \n41   0.530435  \n3    0.530435  \n40   0.530435  \n155  0.526087  \n8    0.526087  \n10   0.526087  \n9    0.526087  \n43   0.523913  \n23   0.519565  \n13   0.519565  \n4    0.519565  \n26   0.519565  \n14   0.519565  \n15   0.517391  \n2    0.517391  \n0    0.517391  \n1    0.517391  \n21   0.510870  \n7    0.510870  \n6    0.510870  \n5    0.510870  \n17   0.506522  \n19   0.506522  \n20   0.504348  \n22   0.502174  \n16   0.489130  \n\n[999 rows x 7 columns]"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=['roc_auc'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_values():\n",
    "    pred = []\n",
    "    \n",
    "    pred.append(knn_f1()[0])\n",
    "    pred.append(knn_roc_auc()[0])\n",
    "    pred.append(knn_precision()[0])\n",
    "    pred.append(knn_recall()[0])\n",
    "    pred.append(knn_accuracy()[0])\n",
    "    \n",
    "    pred.append(mlp_f1()[0])\n",
    "    pred.append(mlp_roc_auc()[0])\n",
    "    pred.append(mlp_precision()[0])\n",
    "    pred.append(mlp_recall()[0])\n",
    "    pred.append(mlp_accuracy()[0])\n",
    "    \n",
    "    pred.append(lda_f1()[0])\n",
    "    pred.append(lda_roc_auc()[0])\n",
    "    pred.append(lda_precision()[0])\n",
    "    pred.append(lda_recall()[0])\n",
    "    pred.append(lda_accuracy()[0])\n",
    "    \n",
    "    pred.append(qda_f1()[0])\n",
    "    pred.append(qda_roc_auc()[0])\n",
    "    pred.append(qda_precision()[0])\n",
    "    pred.append(qda_recall()[0])\n",
    "    pred.append(qda_accuracy()[0])\n",
    "    \n",
    "    pred.append(svc_f1()[0])\n",
    "    pred.append(svc_roc_auc()[0])\n",
    "    pred.append(svc_precision()[0])\n",
    "    pred.append(svc_recall()[0])\n",
    "    pred.append(svc_accuracy()[0])\n",
    "    \n",
    "    pred.append(lgbm()[0])\n",
    "    pred.append(xgb()[0])\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_values():\n",
    "    pred = []\n",
    "    \n",
    "    pred.append(knn_f1()[1])\n",
    "    pred.append(knn_roc_auc()[1])\n",
    "    pred.append(knn_precision()[1])\n",
    "    pred.append(knn_recall()[1])\n",
    "    pred.append(knn_accuracy()[1])\n",
    "    \n",
    "    pred.append(mlp_f1()[1])\n",
    "    pred.append(mlp_roc_auc()[1])\n",
    "    pred.append(mlp_precision()[1])\n",
    "    pred.append(mlp_recall()[1])\n",
    "    pred.append(mlp_accuracy()[1])\n",
    "    \n",
    "    pred.append(lda_f1()[1])\n",
    "    pred.append(lda_roc_auc()[1])\n",
    "    pred.append(lda_precision()[1])\n",
    "    pred.append(lda_recall()[1])\n",
    "    pred.append(lda_accuracy()[1])\n",
    "    \n",
    "    pred.append(qda_f1()[1])\n",
    "    pred.append(qda_roc_auc()[1])\n",
    "    pred.append(qda_precision()[1])\n",
    "    pred.append(qda_recall()[1])\n",
    "    pred.append(qda_accuracy()[1])\n",
    "    \n",
    "    pred.append(svc_f1()[1])\n",
    "    pred.append(svc_roc_auc()[1])\n",
    "    pred.append(svc_precision()[1])\n",
    "    pred.append(svc_recall()[1])\n",
    "    pred.append(svc_accuracy()[1])\n",
    "    \n",
    "    pred.append(lgbm()[1])\n",
    "    pred.append(xgb()[1]) # best at SelectKBest(score_func=chi2,k=859) and SelectFromModel(LinearDiscriminantAnalysis()) two times\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "precision    recall  f1-score   support\n\n           0       0.84      0.21      0.34       230\n           1       0.55      0.96      0.70       230\n\n    accuracy                           0.59       460\n   macro avg       0.70      0.59      0.52       460\nweighted avg       0.70      0.59      0.52       460\n\nf1_score ::  0.6993670886075949\n              precision    recall  f1-score   support\n\n           0       0.72      0.43      0.54       230\n           1       0.59      0.83      0.69       230\n\n    accuracy                           0.63       460\n   macro avg       0.66      0.63      0.62       460\nweighted avg       0.66      0.63      0.62       460\n\nroc_auc_score ::  0.6304347826086956\n              precision    recall  f1-score   support\n\n           0       0.72      0.43      0.54       230\n           1       0.59      0.83      0.69       230\n\n    accuracy                           0.63       460\n   macro avg       0.66      0.63      0.62       460\nweighted avg       0.66      0.63      0.62       460\n\nprecision ::  0.5773697002430461\n              precision    recall  f1-score   support\n\n           0       0.87      0.17      0.28       230\n           1       0.54      0.97      0.69       230\n\n    accuracy                           0.57       460\n   macro avg       0.70      0.57      0.49       460\nweighted avg       0.70      0.57      0.49       460\n\nrecall_score ::  0.9739130434782609\n              precision    recall  f1-score   support\n\n           0       0.72      0.43      0.54       230\n           1       0.59      0.83      0.69       230\n\n    accuracy                           0.63       460\n   macro avg       0.66      0.63      0.62       460\nweighted avg       0.66      0.63      0.62       460\n\naccuracy ::  0.6304347826086957\n              precision    recall  f1-score   support\n\n           0       0.56      0.48      0.52       230\n           1       0.54      0.62      0.58       230\n\n    accuracy                           0.55       460\n   macro avg       0.55      0.55      0.55       460\nweighted avg       0.55      0.55      0.55       460\n\nrecall_score ::  0.5801217038539555\n              precision    recall  f1-score   support\n\n           0       0.61      0.68      0.64       230\n           1       0.64      0.56      0.59       230\n\n    accuracy                           0.62       460\n   macro avg       0.62      0.62      0.62       460\nweighted avg       0.62      0.62      0.62       460\n\nroc_auc_score ::  0.6195652173913044\n              precision    recall  f1-score   support\n\n           0       0.60      0.71      0.65       230\n           1       0.65      0.53      0.58       230\n\n    accuracy                           0.62       460\n   macro avg       0.62      0.62      0.62       460\nweighted avg       0.62      0.62      0.62       460\n\naverage_precision_score ::  0.5771796641361859\n              precision    recall  f1-score   support\n\n           0       0.57      0.02      0.03       230\n           1       0.50      0.99      0.66       230\n\n    accuracy                           0.50       460\n   macro avg       0.54      0.50      0.35       460\nweighted avg       0.54      0.50      0.35       460\n\nrecall_score ::  0.9869565217391304\n              precision    recall  f1-score   support\n\n           0       0.59      0.66      0.62       230\n           1       0.62      0.55      0.58       230\n\n    accuracy                           0.60       460\n   macro avg       0.61      0.60      0.60       460\nweighted avg       0.61      0.60      0.60       460\n\naccuracy ::  0.6043478260869565\n              precision    recall  f1-score   support\n\n           0       0.65      0.62      0.63       230\n           1       0.64      0.67      0.65       230\n\n    accuracy                           0.64       460\n   macro avg       0.64      0.64      0.64       460\nweighted avg       0.64      0.64      0.64       460\n\nf1 ::  0.6525423728813559\n              precision    recall  f1-score   support\n\n           0       0.65      0.62      0.63       230\n           1       0.64      0.67      0.65       230\n\n    accuracy                           0.64       460\n   macro avg       0.64      0.64      0.64       460\nweighted avg       0.64      0.64      0.64       460\n\nroc_auc ::  0.6434782608695652\n              precision    recall  f1-score   support\n\n           0       0.65      0.62      0.63       230\n           1       0.64      0.67      0.65       230\n\n    accuracy                           0.64       460\n   macro avg       0.64      0.64      0.64       460\nweighted avg       0.64      0.64      0.64       460\n\naverage_precision ::  0.5913043478260869\n              precision    recall  f1-score   support\n\n           0       0.65      0.62      0.63       230\n           1       0.64      0.67      0.65       230\n\n    accuracy                           0.64       460\n   macro avg       0.64      0.64      0.64       460\nweighted avg       0.64      0.64      0.64       460\n\nrecall ::  0.6695652173913044\n              precision    recall  f1-score   support\n\n           0       0.65      0.62      0.63       230\n           1       0.64      0.67      0.65       230\n\n    accuracy                           0.64       460\n   macro avg       0.64      0.64      0.64       460\nweighted avg       0.64      0.64      0.64       460\n\naccuracy ::  0.6434782608695652\n              precision    recall  f1-score   support\n\n           0       0.60      0.50      0.54       230\n           1       0.57      0.67      0.62       230\n\n    accuracy                           0.58       460\n   macro avg       0.59      0.58      0.58       460\nweighted avg       0.59      0.58      0.58       460\n\nf1 ::  0.616\n              precision    recall  f1-score   support\n\n           0       0.62      0.71      0.66       230\n           1       0.66      0.56      0.61       230\n\n    accuracy                           0.64       460\n   macro avg       0.64      0.64      0.63       460\nweighted avg       0.64      0.64      0.63       460\n\nroc_auc ::  0.6369565217391305\n              precision    recall  f1-score   support\n\n           0       0.62      0.71      0.66       230\n           1       0.66      0.56      0.61       230\n\n    accuracy                           0.64       460\n   macro avg       0.64      0.64      0.63       460\nweighted avg       0.64      0.64      0.63       460\n\nprecision ::  0.5906020066889632\n              precision    recall  f1-score   support\n\n           0       0.55      0.34      0.42       230\n           1       0.52      0.72      0.61       230\n\n    accuracy                           0.53       460\n   macro avg       0.54      0.53      0.52       460\nweighted avg       0.54      0.53      0.52       460\n\nrecall ::  0.7217391304347827\n              precision    recall  f1-score   support\n\n           0       0.62      0.71      0.66       230\n           1       0.66      0.56      0.61       230\n\n    accuracy                           0.64       460\n   macro avg       0.64      0.64      0.63       460\nweighted avg       0.64      0.64      0.63       460\n\naccuracy ::  0.6369565217391304\n              precision    recall  f1-score   support\n\n           0       0.63      0.65      0.64       230\n           1       0.64      0.63      0.63       230\n\n    accuracy                           0.64       460\n   macro avg       0.64      0.64      0.64       460\nweighted avg       0.64      0.64      0.64       460\n\nf1 ::  0.6329670329670329\n              precision    recall  f1-score   support\n\n           0       0.63      0.65      0.64       230\n           1       0.64      0.63      0.63       230\n\n    accuracy                           0.64       460\n   macro avg       0.64      0.64      0.64       460\nweighted avg       0.64      0.64      0.64       460\n\nroc_auc ::  0.6369565217391304\n              precision    recall  f1-score   support\n\n           0       0.63      0.65      0.64       230\n           1       0.64      0.63      0.63       230\n\n    accuracy                           0.64       460\n   macro avg       0.64      0.64      0.64       460\nweighted avg       0.64      0.64      0.64       460\n\naverage_precision ::  0.5876521739130435\n              precision    recall  f1-score   support\n\n           0       0.63      0.65      0.64       230\n           1       0.64      0.63      0.63       230\n\n    accuracy                           0.64       460\n   macro avg       0.64      0.64      0.64       460\nweighted avg       0.64      0.64      0.64       460\n\nrecall ::  0.6260869565217392\n              precision    recall  f1-score   support\n\n           0       0.63      0.65      0.64       230\n           1       0.64      0.63      0.63       230\n\n    accuracy                           0.64       460\n   macro avg       0.64      0.64      0.64       460\nweighted avg       0.64      0.64      0.64       460\n\naccuracy ::  0.6369565217391304\naccuracy, precision, recall, f1_score, roc_auc_score::  0.6695652173913044 0.6203366058906031 0.5739130434782609 0.6346153846153847 0.6695652173913044\n"
    }
   ],
   "source": [
    "X_train_2 = np.array(get_train_values())\n",
    "X_test_2 = np.array(get_test_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier().fit(X_train,y_train)\n",
    "pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,pred))\n",
    "\n",
    "print('accuracy : ',accuracy_score(y_test,pred))\n",
    "print('precision : ',average_precision_score(y_test,pred))\n",
    "print('f1_score : ',f1_score(y_test,pred))\n",
    "print('recall_score : ',recall_score(y_test,pred))\n",
    "print('roc_auc : ',roc_auc_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,len(list(X_train_2)[0])):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier().fit(X_train_2,y_train)\n",
    "pred = model.predict(X_test_2)\n",
    "\n",
    "print(classification_report(y_test,pred))\n",
    "\n",
    "print('accuracy : ',accuracy_score(y_test,pred))\n",
    "print('precision : ',average_precision_score(y_test,pred))\n",
    "print('f1_score : ',f1_score(y_test,pred))\n",
    "print('recall_score : ',recall_score(y_test,pred))\n",
    "print('roc_auc : ',roc_auc_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "tdf = df.DataFrame(X_train_2)\n",
    "tdf.corr()"
   ]
  }
 ]
}