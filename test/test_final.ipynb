{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bit5cbe49f610aa411e8c53eb13e742ec54",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import multiprocessing\n",
    "import sys,os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "# from preprocessing.Normalize import Normalize\n",
    "# import helper.SeriesHelper as series_helper\n",
    "import time\n",
    "import pickle\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "import warnings\n",
    "from preprocessing.Normalize import Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = multiprocessing.Manager()\n",
    "return_list = manager.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def worker(col_beg,col_end,correlation_matrix,process_count):\n",
    "    '''worker function'''\n",
    "    t = time.time()\n",
    "    print(\"*****\"*5,process_count,\" Process started\",\"*****\"*5,)\n",
    "    correlated_features = []\n",
    "    for i in range(col_beg,col_end,1):\n",
    "        for j in range(i):\n",
    "            if j!=0:\n",
    "                try:\n",
    "                    if abs(correlation_matrix.iloc[i, j]) > 0.8:\n",
    "                        colname = correlation_matrix.columns[i]\n",
    "                        correlated_features.append([colname,correlation_matrix.iloc[i, 0],correlation_matrix.iloc[i, j]])\n",
    "                except Exception as e:\n",
    "                    print(\"*****\"*10,\"EXCEPTION\",\"*****\"*10)\n",
    "                    print(\"Exception :: \",e)\n",
    "                    print(\"i,j :: \",i,j)\n",
    "                    print(f'Number of rows: {len(correlation_matrix):,}.')\n",
    "                    print(\"Number of Columns :: \",str(len(correlation_matrix.columns)))\n",
    "                    print(\"*****\"*10,\"END EXCEPTION\",\"*****\"*10)\n",
    "    return_list += correlated_features\n",
    "    print(\"--\"*5,\"No of features to remove : \",str(len(return_list)),\"--\"*5)\n",
    "    print(\"Time Required  for loop : \",time.time()-t)\n",
    "    print(process_count,\" Chunk Process Ended\")\n",
    "    print(\"*****\"*5,\"  \",process_count,\" CHUNK END \",\"  \",\"*****\"*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = Normalize()\n",
    "normal_matrix = n.get_normalized_data()\n",
    "del n\n",
    "del Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Start Creating Correlation Matrix\n"
    }
   ],
   "source": [
    "corr_time = time.time()\n",
    "print(\"Start Creating Correlation Matrix\")\n",
    "correlation_matrix = normal_matrix.corr()\n",
    "print(\"Correlation Matrix Shape ::: \",correlation_matrix.shape)\n",
    "del corr_time\n",
    "del normal_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []\n",
    "step = 4000\n",
    "process_count = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(correlation_matrix.columns),step):\n",
    "   worker(i,i+step,correlation_matrix,process_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,len(return_list),1):\n",
    "        print(x,\"\\t\",x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RETURN LIST COUNT : \",len(return_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('return_list.list', 'wb') as save_file: \n",
    "        # Step 3\n",
    "        pickle.dump(return_list, save_file)\n",
    "    print(\"TOTAL TIME REQURIED :: \",time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}