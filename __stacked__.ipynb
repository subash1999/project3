{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36864bit5cbe49f610aa411e8c53eb13e742ec54",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "Using TensorFlow backend.\n"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, SelectFdr, SelectFpr, SelectFwe\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import RFE,RFECV\n",
    "from sklearn.feature_selection import chi2,f_classif, mutual_info_classif\n",
    "from sklearn.model_selection import ParameterGrid, GridSearchCV\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "from sklearn.linear_model import LogisticRegression,LassoCV, Lasso\n",
    "from sklearn.ensemble import ExtraTreesClassifier, BaggingClassifier, VotingClassifier, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.metrics import  accuracy_score,auc,average_precision_score,roc_auc_score, recall_score,f1_score, log_loss, fbeta_score, confusion_matrix, precision_recall_curve,classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from tpot import TPOTClassifier\n",
    "from ReliefF import ReliefF\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE,SMOTENC,ADASYN, BorderlineSMOTE, KMeansSMOTE, SVMSMOTE,RandomOverSampler\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from sklearn.preprocessing import Normalizer,normalize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier,GradientBoostingClassifier,StackingClassifier,VotingClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import pickle\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from matplotlib import pyplot\n",
    "import time\n",
    "from multiprocessing import Process,Pool,Manager\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing.Normalize import Normalize\n",
    "import helper.SeriesHelper as series_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = Normalize().get_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model,temp_X_train,temp_y_train,temp_X_test,temp_y_test):\n",
    " \n",
    "    xtr = temp_X_train\n",
    "    xte = temp_X_test\n",
    "    model = model.fit(xtr,temp_y_train)\n",
    "    # knn = MLPClassifier().fit(xtr,temp_y_train)\n",
    "    pred = model.predict(xte)\n",
    "\n",
    "    acc  = accuracy_score(temp_y_test,pred)\n",
    "    prec = average_precision_score(temp_y_test,pred)\n",
    "    recall = recall_score(temp_y_test,pred)\n",
    "    f1 = f1_score(temp_y_test,pred)\n",
    "    roc_auc = roc_auc_score(temp_y_test,pred)\n",
    "\n",
    "    return [acc,prec,recall,f1,roc_auc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "borderline = BorderlineSMOTE(random_state=27,k_neighbors=30,n_jobs=6,m_neighbors=10)\n",
    "temp_X_train, temp_y_train = borderline.fit_sample(X_train, y_train)\n",
    "borderline = BorderlineSMOTE(random_state=27,k_neighbors=30,n_jobs=6,m_neighbors=10)\n",
    "temp_X_test,temp_y_test = borderline.fit_sample(X_test, y_test)\n",
    "# temp_X_test,temp_y_test = X_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr,ytr = temp_X_train,temp_y_train\n",
    "xte,yte = temp_X_test, temp_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = SelectKBest(score_func=chi2,k=79).fit(xtr,ytr)\n",
    "xtr = best.transform(xtr)\n",
    "xte = best.transform(xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "xtr = model.transform(xtr)\n",
    "xte = model.transform(xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelectFromModel(LinearDiscriminantAnalysis()).fit(xtr,ytr)\n",
    "xtr = model.transform(xtr)\n",
    "xte = model.transform(xte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "svc = SVC(probability=True,random_state=42)\n",
    "knn = KNeighborsClassifier(n_neighbors=35)\n",
    "mlp_hidden = MLPClassifier(hidden_layer_sizes=(300,200,100,50,100,200),random_state=42)\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lsvc = LinearSVC(random_state=42)\n",
    "nusvc = NuSVC(probability=True)\n",
    "perceptron = Perceptron(random_state=42)\n",
    "nc = NearestCentroid()\n",
    "xgc = XGBClassifier(random_state=42,n_jobs=7)\n",
    "lgbm = LGBMClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[0.5891304347826087,\n 0.5527588223825307,\n 0.5739130434782609,\n 0.5827814569536424,\n 0.5891304347826087]"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_scores(lsvc,xtr,ytr,xte,yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}